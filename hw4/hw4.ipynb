{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0143ca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22193136",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import main_functions as main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c101d962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_confusion_matrix(confusion, accuracy, label_classes, name):\n",
    "    plt.title(\"{}, accuracy = {:.3f}\".format(name, accuracy))\n",
    "    plt.imshow(confusion)\n",
    "    ax, fig = plt.gca(), plt.gcf()\n",
    "    plt.xticks(np.arange(len(label_classes)), label_classes)\n",
    "    plt.yticks(np.arange(len(label_classes)), label_classes)\n",
    "    ax.set_xticks(np.arange(len(label_classes) + 1) - .5, minor=True)\n",
    "    ax.set_yticks(np.arange(len(label_classes) + 1) - .5, minor=True)\n",
    "    ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "151f7b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = sio.loadmat('./mnist_train.mat')\n",
    "mnist_test = sio.loadmat('./mnist_test.mat')\n",
    "im_train, label_train = mnist_train['im_train'], mnist_train['label_train']\n",
    "im_test, label_test = mnist_test['im_test'], mnist_test['label_test']\n",
    "batch_size = 32\n",
    "im_train, im_test = im_train / 255.0, im_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1749b065",
   "metadata": {},
   "source": [
    "# SLP Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7408e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mini_batch(im_train, label_train, batch_size):\n",
    "    ## For ease of batching\n",
    "    im_swp = np.swapaxes(im_train,0,1)\n",
    "    lab_swp = np.swapaxes(label_train,0,1)\n",
    "    \n",
    "    ## One hot encoding\n",
    "    oh_lab_swp = []\n",
    "    for lab in lab_swp:\n",
    "        oh = np.zeros(10)\n",
    "        oh[lab] = 1\n",
    "        oh_lab_swp.append(oh)\n",
    "    \n",
    "    seed = 527\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(im_swp)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(oh_lab_swp)\n",
    "    \n",
    "    mini_batch_x = np.array(np.array_split(im_swp,batch_size))#.reshape((-1,196,32))\n",
    "    mini_batch_y = np.array(np.array_split(oh_lab_swp,batch_size))#.reshape((-1,10,32))\n",
    "    \n",
    "    return mini_batch_x,mini_batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20da11fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc(x, w, b):\n",
    "    if len(x.shape) > 1:\n",
    "        x = x.flatten()\n",
    "    y = np.dot(w,x) + b\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eaf7d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_euclidian(y_tilde, y):\n",
    "    l = np.linalg.norm(y_tilde-y)**2\n",
    "    dl_dy = 2*(y_tilde-y)\n",
    "    \n",
    "    return l, dl_dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f57ff03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_backward(dl_dy, x, w, b, y):\n",
    "    dl_dx = np.dot(w.T,dl_dy)\n",
    "    dl_dw = np.outer(dl_dy,x)\n",
    "    dl_db = dl_dy\n",
    "\n",
    "    return dl_dx, dl_dw, dl_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46f702fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_slp_linear(mini_batch_x, mini_batch_y):\n",
    "    batch_size,batches,size_img = mini_batch_x.shape\n",
    "    n = 10\n",
    "    m = size_img\n",
    "    lr = 1e-4\n",
    "    dr = 0.9\n",
    "    w = np.random.normal(0, 1, size=(n,m))\n",
    "    b = np.zeros((n))\n",
    "    k = 0\n",
    "\n",
    "    for itr in range(10000):\n",
    "        if itr % 1000 == 0:\n",
    "            lr *= dr\n",
    "\n",
    "        dl_dw = 0\n",
    "        dl_db = 0\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            x = mini_batch_x[:,k][i]\n",
    "            y = mini_batch_y[:,k][i]\n",
    "            \n",
    "            y_tilde = fc(x, w, b)\n",
    "            l,dl_dy = loss_euclidian(y_tilde, y)\n",
    "            dl_dx, dl_dw_n, dl_db_n = fc_backward(dl_dy, x, w, b, y)\n",
    "\n",
    "            dl_dw += dl_dw_n\n",
    "            dl_db += dl_db_n\n",
    "\n",
    "        k += 1\n",
    "        if k >= batches:\n",
    "            k = 0\n",
    "\n",
    "        w -= (lr * dl_dw)\n",
    "        b -= (lr * dl_db)\n",
    "        \n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "299977bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main.main_slp_linear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e425885",
   "metadata": {},
   "source": [
    "# SLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfe3a10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_cross_entropy_softmax(x, y):\n",
    "    def softmax(x):\n",
    "        return np.exp(x) / np.sum(np.exp(x))\n",
    "    \n",
    "    l = -1 * (np.sum(y*np.log(1e-9 + softmax(x))) / len(y))\n",
    "    dl_dy = softmax(x) - y\n",
    "    \n",
    "    return l, dl_dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a521ea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_slp(mini_batch_x, mini_batch_y):\n",
    "    batch_size,batches,size_img = mini_batch_x.shape\n",
    "    n = 10\n",
    "    m = size_img\n",
    "    lr = 1e-3\n",
    "    dr = 0.9\n",
    "    w = np.random.normal(0, 0.5, size=(n,m))\n",
    "    b = np.zeros((n))\n",
    "    k = 0\n",
    "\n",
    "    for itr in range(10000):\n",
    "        if itr % 1000 == 0:\n",
    "            lr *= dr\n",
    "\n",
    "        dl_dw = 0\n",
    "        dl_db = 0\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            x = mini_batch_x[:,k][i]\n",
    "            y = mini_batch_y[:,k][i]\n",
    "            \n",
    "            fc_out = fc(x, w, b)\n",
    "            l,dl_dy = loss_cross_entropy_softmax(fc_out, y)\n",
    "            dl_dx, dl_dw_n, dl_db_n = fc_backward(dl_dy, x, w, b, y)\n",
    "\n",
    "            dl_dw += dl_dw_n\n",
    "            dl_db += dl_db_n\n",
    "\n",
    "        k += 1\n",
    "        if k >= batches:\n",
    "            k = 0\n",
    "\n",
    "        w -= (lr * dl_dw)\n",
    "        b -= (lr * dl_db)\n",
    "        \n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54a56a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main.main_slp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0871524",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "id": "3304d211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(x*1e-2,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "id": "8512ff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(dl_dy, x, y):\n",
    "    dl_dx = (x > 0).astype(int)\n",
    "    return np.where(dl_dx==0., 0.01, dl_dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "id": "9180ece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batch_x,mini_batch_y = get_mini_batch(im_train, label_train, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "id": "9503b5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "id": "4a654643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0010027885437011719\n",
      "0\n",
      "29.65001630783081\n",
      "10000\n",
      "29.685959815979004\n",
      "20000\n",
      "29.66893768310547\n",
      "30000\n",
      "29.93994450569153\n",
      "40000\n",
      "29.784934759140015\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "batch_size,batches,size_img = mini_batch_x.shape\n",
    "n = 10\n",
    "m = size_img\n",
    "lr = 1e-3\n",
    "dr = 0.9\n",
    "w1 = np.random.normal(0, 1, size=(30,196))\n",
    "w2 = np.random.normal(0, 1, size=(10,30))\n",
    "b1 = np.zeros((30))\n",
    "b2 = np.zeros((10))\n",
    "k = 0\n",
    "_ = None\n",
    "\n",
    "st = t.time()\n",
    "\n",
    "for itr in range(60000):\n",
    "\n",
    "    if itr % 1000 == 0: \n",
    "        lr *= dr\n",
    "\n",
    "    if itr % 10000 == 0:\n",
    "        end = t.time()\n",
    "        print(end-st)\n",
    "        st = t.time()\n",
    "        print(itr)\n",
    "\n",
    "    dl_dw_1 = 0\n",
    "    dl_dw_2 = 0\n",
    "    dl_db_1 = 0\n",
    "    dl_db_2 = 0\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        x = mini_batch_x[:,k][i]\n",
    "        y = mini_batch_y[:,k][i]\n",
    "        \n",
    "        ## Forward\n",
    "        fc_1 = fc(x, w1, b1)\n",
    "        relu_ = relu(fc_1)\n",
    "        fc_2 = fc(relu_, w2, b2)\n",
    "        l,dl_dy = loss_cross_entropy_softmax(fc_2, y)\n",
    "        \n",
    "        ## Backward\n",
    "        dl_dx_2, dl_dw_n_2, dl_db_n_2 = fc_backward(dl_dy, relu_, w2, _, _)  \n",
    "        dl_dx_relu = relu_backward(dl_dx_2, fc_1, _)\n",
    "        dl_dx_1, dl_dw_n_1, dl_db_n_1 = fc_backward(dl_dx_relu, x, w1, _, _)\n",
    "\n",
    "        dl_dw_1 += dl_dw_n_1\n",
    "        dl_db_1 += dl_db_n_1\n",
    "        dl_dw_2 += dl_dw_n_2\n",
    "        dl_db_2 += dl_db_n_2\n",
    "\n",
    "    k += 1\n",
    "    if k >= batches:\n",
    "        k = 0\n",
    "\n",
    "    w1 -= (lr * dl_dw_1)\n",
    "    b1 -= (lr * dl_db_1)\n",
    "    w2 -= (lr * dl_dw_2)\n",
    "    b2 -= (lr * dl_db_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "id": "28f136d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist_train = sio.loadmat('./mnist_train.mat')\n",
    "mnist_test = sio.loadmat('./mnist_test.mat')\n",
    "im_train, label_train = mnist_train['im_train'], mnist_train['label_train']\n",
    "im_test, label_test = mnist_test['im_test'], mnist_test['label_test']\n",
    "batch_size = 32\n",
    "im_train, im_test = im_train / 255.0, im_test / 255.0\n",
    "mini_batch_x, mini_batch_y = get_mini_batch(im_train, label_train, batch_size)\n",
    "#w1, b1, w2, b2 = train_mlp(mini_batch_x, mini_batch_y)\n",
    "sio.savemat('mlp.mat', mdict={'w1': w1, 'b1': b1, 'w2': w2, 'b2': b2})\n",
    "\n",
    "acc = 0\n",
    "confusion = np.zeros((10, 10))\n",
    "num_test = im_test.shape[1]\n",
    "for i in range(num_test):\n",
    "    x = im_test[:, [i]]\n",
    "    pred1 = fc(x, w1, b1)\n",
    "    pred2 = relu(pred1)\n",
    "    y = fc(pred2, w2, b2)\n",
    "    l_pred = np.argmax(y)\n",
    "    confusion[l_pred, label_test[0, i]] = confusion[l_pred, label_test[0, i]] + 1\n",
    "\n",
    "    if l_pred == label_test[0, i]:\n",
    "        acc = acc + 1\n",
    "accuracy = acc / num_test\n",
    "for i in range(10):\n",
    "    confusion[:, i] = confusion[:, i] / np.sum(confusion[:, i])\n",
    "\n",
    "label_classes = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "visualize_confusion_matrix(confusion, accuracy, label_classes, 'Multi-layer Perceptron Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1375d414",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "e41a8129",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Copied from \n",
    "## https://leonardoaraujosantos.gitbook.io/artificial-inteligence\n",
    "## /machine_learning/deep_learning/convolution_layer/making_faster#im2col-and-col2im-sources-in-python\n",
    "def im2col(x,hh,ww,stride):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      x: image matrix to be translated into columns, (C,H,W)\n",
    "      hh: filter height\n",
    "      ww: filter width\n",
    "      stride: stride\n",
    "    Returns:\n",
    "      col: (new_h*new_w,hh*ww*C) matrix, each column is a cube that will convolve with a filter\n",
    "            new_h = (H-hh) // stride + 1, new_w = (W-ww) // stride + 1\n",
    "    \"\"\"\n",
    "    c,h,w = x.shape\n",
    "    new_h = (h-hh) // stride + 1\n",
    "    new_w = (w-ww) // stride + 1\n",
    "    col = np.zeros([new_h*new_w,c*hh*ww])\n",
    "    for i in range(new_h):\n",
    "       for j in range(new_w):\n",
    "           patch = x[...,i*stride:i*stride+hh,j*stride:j*stride+ww]\n",
    "           col[i*new_w+j,:] = np.reshape(patch,-1)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "b09d263f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(x, w_conv, b_conv):\n",
    "    x = np.array([np.pad(x.reshape((14,14)),1,'constant')])\n",
    "    X = im2col(x,3,3,1)\n",
    "    y = X.dot(w_conv.reshape(9,-1)) + b_conv.reshape(3)\n",
    "\n",
    "    return y.reshape(14,14,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "666b8bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_backward(dl_dy, x, w_conv, b_conv, y):\n",
    "    ## Assuming x is result from conv layer \n",
    "    dl_db = np.sum(dl_dy.reshape(-1,3),axis=0)\n",
    "    dl_dw = dl_dy * x\n",
    "    \n",
    "    return dl_dw, dl_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "id": "55026f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool2x2(x):\n",
    "    out = [[0 for i in range(7)] for i in range(7)]\n",
    "    wk = x.reshape((14,14))\n",
    "    for i in range(0,14,2):\n",
    "        for j in range(0,14,2):\n",
    "            wnd = wk[i:i+2,j:j+2]\n",
    "            out[i//2][j//2] = np.max(wnd)\n",
    "            \n",
    "    return np.array(out).reshape((7,7,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "id": "01b37755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool2x2_backward(dl_dy, x, y):\n",
    "    out = [[0 for i in range(14)] for i in range(14)]\n",
    "    wk = x.reshape((14,14))\n",
    "    for i in range(0,14,2):\n",
    "        for j in range(0,14,2):\n",
    "            wnd = wk[i:i+2,j:j+2]\n",
    "            xx,yy = np.unravel_index(wnd.argmax(), wnd.shape)\n",
    "            out[i+xx][j+yy] = np.max(wnd)\n",
    "            \n",
    "    return np.array(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "id": "61af3cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattening(x):\n",
    "    return np.ravel(x, order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "id": "956aae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattening_backward(dl_dy, x, y):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "id": "e0e7bbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "h,w,c1,c2 = 14,14,1,3\n",
    "x = np.random.normal(0,1,size=(h,w,c1))\n",
    "w_conv = np.random.normal(1,0.1,size=(3,3,1,3))\n",
    "b_conv = np.random.normal(0,0.1,size=(c2,1))\n",
    "\n",
    "y = conv(x, w_conv, b_conv)\n",
    "l,dl_dy = loss_cross_entropy_softmax(x,y)\n",
    "dl_dw, dl_db = conv_backward(dl_dy, x, w_conv, b_conv, y)\n",
    "pool = pool2x2(x)\n",
    "back = pool2x2_backward(dl_dy, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384315bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batch_x,mini_batch_y = get_mini_batch(im_train, label_train, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0615f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size,batches,size_img = mini_batch_x.shape\n",
    "n = 10\n",
    "m = size_img\n",
    "lr = 1e-3\n",
    "dr = 0.9\n",
    "h,w,c1,c2 = 14,14,1,3\n",
    "w_conv = np.random.normal(0,0.1,size=(3,3,1,3))\n",
    "b_conv = np.random.normal(0,0.1,size=(c2,1))\n",
    "w_fc = np.random.normal(0,0.1,size=(10,147))\n",
    "b_fc = np.random.normal(0,0.1,size=(10,1))\n",
    "k = 0\n",
    "_ = None\n",
    "\n",
    "st = t.time()\n",
    "\n",
    "for itr in range(5000):\n",
    "    if itr % 1000 == 0: \n",
    "        lr *= dr\n",
    "\n",
    "    if itr % 10000 == 0:\n",
    "        end = t.time()\n",
    "        print(end-st)\n",
    "        st = t.time()\n",
    "        print(itr)\n",
    "\n",
    "    dl_dw_1 = 0\n",
    "    dl_dw_2 = 0\n",
    "    dl_db_1 = 0\n",
    "    dl_db_2 = 0\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        x = mini_batch_x[:,k][i]\n",
    "        y = mini_batch_y[:,k][i]\n",
    "        \n",
    "        ## Forward\n",
    "        conv_1 = conv(x, w_conv, b_conv)\n",
    "        relu_1 = relu(conv_1)\n",
    "        pooled = pool2x2(relu_1)\n",
    "        flattened = flattening(pooled)\n",
    "        fc_1 = fc(flattened, w_fc, b_fc)\n",
    "        l,dl_dy = loss_cross_entropy_softmax(fc_1,y)\n",
    "        \n",
    "        ## Backward\n",
    "        dl_dx_2, dl_dw_n_2, dl_db_n_2 = fc_backward(dl_dy, flattened, w_fc, b_fc, y)  \n",
    "        dl_dx_1 = flattening_backward(dl_dy, pooled, y)\n",
    "        pool_back = pool2x2_backward(dl_dy, relu_1, y)\n",
    "        relu_back = relu_backward(dl_dy, conv_1, y)\n",
    "        conv_back = conv_backward(dl_dy, x, w_conv, b_conv, y)\n",
    "        \n",
    "        \n",
    "## TODO\n",
    "\n",
    "    k += 1\n",
    "    if k >= batches:\n",
    "        k = 0\n",
    "\n",
    "## TODO\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
